{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/kornia/kornia\n",
      "  Cloning https://github.com/kornia/kornia to /tmp/pip-req-build-mbr9urla\n",
      "  Running command git clone -q https://github.com/kornia/kornia /tmp/pip-req-build-mbr9urla\n",
      "Requirement already satisfied, skipping upgrade: numpy in /home/mishkdmy/.conda/envs/fastai1/lib/python3.7/site-packages (from kornia==0.4.1+0c9e625) (1.18.0)\n",
      "Requirement already satisfied, skipping upgrade: torch<1.7.0,>=1.6.0 in /home/mishkdmy/.local/lib/python3.7/site-packages (from kornia==0.4.1+0c9e625) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: future in /home/mishkdmy/.local/lib/python3.7/site-packages (from torch<1.7.0,>=1.6.0->kornia==0.4.1+0c9e625) (0.18.2)\n",
      "Building wheels for collected packages: kornia\n",
      "  Building wheel for kornia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kornia: filename=kornia-0.4.1+0c9e625-py2.py3-none-any.whl size=206171 sha256=08a2801e03669cb42247fa83bb6b4b996230e6ec62baaca632fb7bbb1c745184\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-yr06tdqf/wheels/5f/8b/92/375714dc479253f78ed777dd105d79f9693448dcfef85c8163\n",
      "Successfully built kornia\n",
      "Installing collected packages: kornia\n",
      "  Found existing installation: kornia 0.4.1+0c9e625\n",
      "    Uninstalling kornia-0.4.1+0c9e625:\n",
      "      Successfully uninstalled kornia-0.4.1+0c9e625\n",
      "Successfully installed kornia-0.4.1+0c9e625\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/kornia/kornia --user --upgrade\n",
    "#!pip install pytorch_metric_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastscript\n",
      "  Downloading https://files.pythonhosted.org/packages/60/e4/7790e3ca100841566fdc1ccee413b9a9d40629d1858d86b1b9ffbc4fa75a/fastscript-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: packaging in /home/mishkdmy/.conda/envs/fastai1/lib/python3.7/site-packages (from fastscript) (19.2)\n",
      "Requirement already satisfied: pip in /home/mishkdmy/.conda/envs/fastai1/lib/python3.7/site-packages (from fastscript) (19.3.1)\n",
      "Requirement already satisfied: six in /home/mishkdmy/.conda/envs/fastai1/lib/python3.7/site-packages (from packaging->fastscript) (1.13.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/mishkdmy/.conda/envs/fastai1/lib/python3.7/site-packages (from packaging->fastscript) (2.4.5)\n",
      "Installing collected packages: fastscript\n",
      "\u001b[33m  WARNING: The script test_fastscript is installed in '/home/mishkdmy/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed fastscript-1.0.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install fastscript --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import random\n",
    "import numpy as np\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from fastai2.basics import *\n",
    "from fastcore import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.callback.all import *\n",
    "from fastprogress import fastprogress\n",
    "from fastai2.callback.mixup import *\n",
    "from fastscript import *\n",
    "import torchvision as tv\n",
    "import kornia as K\n",
    "import gc\n",
    "from pytorch_metric_learning import losses, miners\n",
    "\n",
    "def imshow_torch(tensor, *kwargs):\n",
    "    plt.figure()\n",
    "    plt.imshow(K.tensor_to_image(tensor), *kwargs)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_name = 'liberty'\n",
    "val_ds_names = ['notredame', 'yosemite']\n",
    "\n",
    "ds_root = '/home/mishkdmy/datasets/Brown/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Any, Callable, List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import VisionDataset\n",
    "\n",
    "from torchvision.datasets.utils import download_url\n",
    "\n",
    "from fastai2  import *\n",
    "\n",
    "\n",
    "class PhotoTourRevisited(torchvision.datasets.VisionDataset):\n",
    "    \"\"\"`Learning Local Image Descriptors Data <http://phototour.cs.washington.edu/patches/default.htm>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory where images are.\n",
    "        name (string): Name of the dataset to load.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "    \"\"\"\n",
    "    urls = {\n",
    "        'notredame_harris': [\n",
    "            'http://matthewalunbrown.com/patchdata/notredame_harris.zip',\n",
    "            'notredame_harris.zip',\n",
    "            '69f8c90f78e171349abdf0307afefe4d'\n",
    "        ],\n",
    "        'yosemite_harris': [\n",
    "            'http://matthewalunbrown.com/patchdata/yosemite_harris.zip',\n",
    "            'yosemite_harris.zip',\n",
    "            'a73253d1c6fbd3ba2613c45065c00d46'\n",
    "        ],\n",
    "        'liberty_harris': [\n",
    "            'http://matthewalunbrown.com/patchdata/liberty_harris.zip',\n",
    "            'liberty_harris.zip',\n",
    "            'c731fcfb3abb4091110d0ae8c7ba182c'\n",
    "        ],\n",
    "        'notredame': [\n",
    "            'http://icvl.ee.ic.ac.uk/vbalnt/notredame.zip',\n",
    "            'notredame.zip',\n",
    "            '509eda8535847b8c0a90bbb210c83484'\n",
    "        ],\n",
    "        'yosemite': [\n",
    "            'http://icvl.ee.ic.ac.uk/vbalnt/yosemite.zip',\n",
    "            'yosemite.zip',\n",
    "            '533b2e8eb7ede31be40abc317b2fd4f0'\n",
    "        ],\n",
    "        'liberty': [\n",
    "            'http://icvl.ee.ic.ac.uk/vbalnt/liberty.zip',\n",
    "            'liberty.zip',\n",
    "            'fdd9152f138ea5ef2091746689176414'\n",
    "        ],\n",
    "    }\n",
    "    means = {'notredame': 0.4854, 'yosemite': 0.4844, 'liberty': 0.4437,\n",
    "             'notredame_harris': 0.4854, 'yosemite_harris': 0.4844, 'liberty_harris': 0.4437}\n",
    "    stds = {'notredame': 0.1864, 'yosemite': 0.1818, 'liberty': 0.2019,\n",
    "            'notredame_harris': 0.1864, 'yosemite_harris': 0.1818, 'liberty_harris': 0.2019}\n",
    "    lens = {'notredame': 468159, 'yosemite': 633587, 'liberty': 450092,\n",
    "            'liberty_harris': 379587, 'yosemite_harris': 450912, 'notredame_harris': 325295}\n",
    "    image_ext = 'bmp'\n",
    "    info_file = 'info.txt'\n",
    "    matches_files = 'm50_100000_100000_0.txt'\n",
    "    img_info_files = 'interest.txt'\n",
    "\n",
    "    def __init__(\n",
    "            self, root: str, name: str, train: bool = False,\n",
    "        transform: Optional[Callable] = None, download: bool = False\n",
    "    ) -> None:\n",
    "        super(PhotoTourRevisited, self).__init__(root)\n",
    "        self.name = name\n",
    "        self.data_dir = os.path.join(self.root, name)\n",
    "        self.data_down = os.path.join(self.root, '{}.zip'.format(name))\n",
    "        self.data_file = os.path.join(self.root, '{}.pt'.format(name))\n",
    "\n",
    "        self.train = train\n",
    "        self.mean = self.means[name]\n",
    "        self.std = self.stds[name]\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_datafile_exists():\n",
    "            raise RuntimeError('Dataset not found.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        # load the serialized data\n",
    "        self.data, self.labels, self.matches, self.img_idxs = torch.load(self.data_file)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Union[torch.Tensor, Tuple[Any, Any, torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (data1, data2, matches)\n",
    "        \"\"\"\n",
    "        data = self.data[index]\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "        if self.train:\n",
    "            return data\n",
    "        return data, self.labels[index], self.img_idxs[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.lens[self.name]\n",
    "\n",
    "\n",
    "    def _check_datafile_exists(self) -> bool:\n",
    "        return os.path.exists(self.data_file)\n",
    "\n",
    "    def _check_downloaded(self) -> bool:\n",
    "        return os.path.exists(self.data_dir)\n",
    "\n",
    "    def download(self) -> None:\n",
    "        if self._check_datafile_exists():\n",
    "            print('# Found cached data {}'.format(self.data_file))\n",
    "            return\n",
    "\n",
    "        if not self._check_downloaded():\n",
    "            # download files\n",
    "            url = self.urls[self.name][0]\n",
    "            filename = self.urls[self.name][1]\n",
    "            md5 = self.urls[self.name][2]\n",
    "            fpath = os.path.join(self.root, filename)\n",
    "\n",
    "            download_url(url, self.root, filename, md5)\n",
    "\n",
    "            print('# Extracting data {}\\n'.format(self.data_down))\n",
    "\n",
    "            import zipfile\n",
    "            with zipfile.ZipFile(fpath, 'r') as z:\n",
    "                z.extractall(self.data_dir)\n",
    "\n",
    "            os.unlink(fpath)\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('# Caching data {}'.format(self.data_file))\n",
    "\n",
    "        dataset = (\n",
    "            read_image_file(self.data_dir, self.image_ext, self.lens[self.name]),\n",
    "            read_info_file(self.data_dir, self.info_file),\n",
    "            read_matches_files(self.data_dir, self.matches_files),\n",
    "            read_interest_file(self.data_dir, self.img_info_files)\n",
    "        )\n",
    "\n",
    "        with open(self.data_file, 'wb') as f:\n",
    "            torch.save(dataset, f)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return \"Split: {}\".format(\"Train\" if self.train is True else \"Test\")\n",
    "\n",
    "\n",
    "def read_image_file(data_dir: str, image_ext: str, n: int) -> torch.Tensor:\n",
    "    \"\"\"Return a Tensor containing the patches\n",
    "    \"\"\"\n",
    "\n",
    "    def PIL2array(_img: Image.Image) -> np.ndarray:\n",
    "        \"\"\"Convert PIL image type to numpy 2D array\n",
    "        \"\"\"\n",
    "        return np.array(_img.getdata(), dtype=np.uint8).reshape(64, 64)\n",
    "\n",
    "    def find_files(_data_dir: str, _image_ext: str) -> List[str]:\n",
    "        \"\"\"Return a list with the file names of the images containing the patches\n",
    "        \"\"\"\n",
    "        files = []\n",
    "        # find those files with the specified extension\n",
    "        for file_dir in os.listdir(_data_dir):\n",
    "            if file_dir.endswith(_image_ext):\n",
    "                files.append(os.path.join(_data_dir, file_dir))\n",
    "        return sorted(files)  # sort files in ascend order to keep relations\n",
    "\n",
    "    patches = []\n",
    "    list_files = find_files(data_dir, image_ext)\n",
    "\n",
    "    for fpath in list_files:\n",
    "        img = Image.open(fpath)\n",
    "        for y in range(0, 1024, 64):\n",
    "            for x in range(0, 1024, 64):\n",
    "                patch = img.crop((x, y, x + 64, y + 64))\n",
    "                patches.append(PIL2array(patch))\n",
    "    return torch.ByteTensor(np.array(patches[:n]))#.float()\n",
    "\n",
    "\n",
    "def read_info_file(data_dir: str, info_file: str) -> torch.Tensor:\n",
    "    \"\"\"Return a Tensor containing the list of labels\n",
    "       Read the file and keep only the ID of the 3D point.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    with open(os.path.join(data_dir, info_file), 'r') as f:\n",
    "        labels = [int(line.split()[0]) for line in f]\n",
    "    return torch.LongTensor(labels)\n",
    "\n",
    "def read_interest_file(data_dir: str, info_file: str) -> torch.Tensor:\n",
    "    \"\"\"Return a Tensor containing the list of image ids\n",
    "       Read the file and keep only the ID of the image point.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    with open(os.path.join(data_dir, info_file), 'r') as f:\n",
    "        labels = [int(line.split()[0]) for line in f]\n",
    "    return torch.LongTensor(labels)\n",
    "\n",
    "\n",
    "def read_matches_files(data_dir: str, matches_file: str) -> torch.Tensor:\n",
    "    \"\"\"Return a Tensor containing the ground truth matches\n",
    "       Read the file and keep only 3D point ID.\n",
    "       Matches are represented with a 1, non matches with a 0.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    with open(os.path.join(data_dir, matches_file), 'r') as f:\n",
    "        for line in f:\n",
    "            line_split = line.split()\n",
    "            matches.append([int(line_split[0]), int(line_split[3]),\n",
    "                            int(line_split[1] == line_split[4])])\n",
    "    return torch.LongTensor(matches)\n",
    "\n",
    "class TupleAug(ItemTransform):\n",
    "    def __init__(self, tfm):\n",
    "        self.tfm = tfm\n",
    "    def encodes(self, o): \n",
    "        out = []\n",
    "        with torch.no_grad():\n",
    "            for i,oi in enumerate(o):\n",
    "                if i < len(o) - 2:\n",
    "                    out.append(self.tfm(oi.float().unsqueeze(1)))\n",
    "                else:\n",
    "                    out.append(oi)\n",
    "        return out\n",
    "#def average_acc_per_th(snn_ratio, is_correct, ths= np.linspace(0,1.0,20) ):\n",
    "#    out = []\n",
    "#    for prev_th, th in zip(ths[:-1], ths[1:]):\n",
    "#        mask = snn_ratio <= th\n",
    "#        #print (mask.sum())\n",
    "#        AA = is_correct[mask].float().mean()\n",
    "#        #print (mask.sum().item(), AA.item())\n",
    "#        out.append(AA.item())\n",
    "#    return out\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1+0c9e625'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.version.__version__\n",
    "\n",
    "desc = K.feature.SOSNet(True)\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TNet(nn.Module):\n",
    "    \"\"\"TFeat model definition\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(TNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.InstanceNorm2d(1, affine=False),\n",
    "            nn.Conv2d(1, 32, kernel_size=7),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=6),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.descr = nn.Sequential(\n",
    "            nn.Linear(64 * 8 * 8, 128),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.descr(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-08 17:43:48--  https://github.com/vbalnt/tfeat/raw/master/pretrained-models/tfeat-liberty.params\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/vbalnt/tfeat/master/pretrained-models/tfeat-liberty.params [following]\n",
      "--2020-09-08 17:43:48--  https://raw.githubusercontent.com/vbalnt/tfeat/master/pretrained-models/tfeat-liberty.params\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.16.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.16.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2400533 (2.3M) [application/octet-stream]\n",
      "Saving to: ‘tfeat-liberty.params’\n",
      "\n",
      "100%[======================================>] 2,400,533   --.-K/s   in 0.1s    \n",
      "\n",
      "2020-09-08 17:43:57 (20.5 MB/s) - ‘tfeat-liberty.params’ saved [2400533/2400533]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/vbalnt/tfeat/raw/master/pretrained-models/tfeat-liberty.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfeat = TNet().eval()\n",
    "tfeat.load_state_dict(torch.load('tfeat-liberty.params'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_descriptor_on_dataset( desc,\n",
    "    ds_name='notredame',\n",
    "    resol=100,\n",
    "    device=torch.device('cuda:0'),\n",
    "    ds_root = '/home/mishkdmy/datasets/Brown'):\n",
    "    \n",
    "    desc.eval()\n",
    "    desc = desc.to(device)\n",
    "    dataset = PhotoTourRevisited(ds_root,\n",
    "                      ds_name,\n",
    "                       train=False, \n",
    "                       download=True)\n",
    "    orig_size = 64\n",
    "    out_size = 32\n",
    "    test_aug = nn.Sequential( \n",
    "        K.Resize((out_size,out_size), interpolation='bicubic'))\n",
    "    BS = 1024\n",
    "    TEST_BS = 128\n",
    "    N_WORKERS = 4\n",
    "    \n",
    "    dl_train = TfmdDL(dataset,\n",
    "                 device=device,\n",
    "                 after_item=[ToTensor], \n",
    "                 after_batch=[TupleAug(test_aug)], #two patches -> single tensor\n",
    "                 bs=BS, num_workers=N_WORKERS,\n",
    "                 shuffle = False)\n",
    "    num_patches = len(dl_train.dataset)\n",
    "    descriptors = []#torch.zeros(num_patches, 128)\n",
    "    all_labels = []#torch.zeros(num_patches)\n",
    "    all_img_labels = []#torch.zeros(num_patches)\n",
    "    Miner = miners.BatchHardMiner()\n",
    "    count = 0 \n",
    "    max_img = -1\n",
    "    min_img = 1000\n",
    "    prec_per_img = []\n",
    "    rec_per_img = []\n",
    "    ths_per_img = []\n",
    "    aps = []\n",
    "    print ('Extracting descriptors and calculating AP')\n",
    "    for patches, labels, img_labels in progress_bar(dl_train):\n",
    "        with torch.no_grad():\n",
    "            descs = desc(patches)\n",
    "            descriptors.append(descs)\n",
    "            all_labels.append(labels)\n",
    "            all_img_labels.append(img_labels)\n",
    "            all_img_labels_cat = torch.cat(all_img_labels)\n",
    "            img_labels_unique = torch.sort(torch.unique(all_img_labels_cat).long())[0]\n",
    "            new_max_img = img_labels_unique.max().item()\n",
    "            new_min_img = img_labels_unique.min().item()\n",
    "            if new_min_img != new_max_img:\n",
    "                all_img_labels = torch.cat(all_img_labels)\n",
    "                descriptors = torch.cat(descriptors)\n",
    "                all_labels = torch.cat(all_labels)\n",
    "                for ii in img_labels_unique[:-1]:\n",
    "                    current_batch = all_img_labels == ii\n",
    "                    cur_descs = descriptors[current_batch].cpu()\n",
    "                    #print (cur_descs.shape)\n",
    "                    cur_labels = all_labels[current_batch].cpu().long()\n",
    "                    NN = cur_labels.size(0)\n",
    "                    pos_matrix = (cur_labels[None].expand(NN,NN) == cur_labels[...,None].expand(NN,NN)) != (torch.eye(NN).to(cur_labels.device)>0)\n",
    "                    #print ('pos_matrix_done')\n",
    "                    neg = torch.zeros(NN).long()\n",
    "                    \n",
    "                    if NN > 2000: # To avoid OOM, we will find hard minimum in batches\n",
    "                        bs1 = 128\n",
    "                        nb = (NN // bs1)  \n",
    "                        for i in range(nb):\n",
    "                            st = i*bs1\n",
    "                            fin = min(NN, (i+1)*bs1)\n",
    "                            if fin == st:\n",
    "                                break\n",
    "                            dm = (torch.cdist(cur_descs[st:fin], cur_descs) +\n",
    "                                  1000.0 * (pos_matrix[st:fin].to(cur_descs.dtype)) + \n",
    "                                1000.0*torch.eye(NN)[st:fin].to(cur_labels.device).to(cur_descs.dtype))\n",
    "                            min_idx = torch.min(dm, dim=1)[1]\n",
    "                            neg[st:fin] = min_idx       \n",
    "                    #anc, pos, neg = Miner(cur_descs, cur_labels)\n",
    "                    pos_idxs = torch.arange(NN)[None].expand(NN,NN)[pos_matrix]\n",
    "                    anc_idxs = torch.nonzero(pos_matrix)[:,0]\n",
    "                    pos_matrix = None\n",
    "                    neg_idxs = neg[anc_idxs]\n",
    "                    pos_dists = F.pairwise_distance(cur_descs[anc_idxs], cur_descs[pos_idxs])\n",
    "                    neg_dists = F.pairwise_distance(cur_descs[anc_idxs], cur_descs[neg_idxs])\n",
    "                    correct = pos_dists <= neg_dists\n",
    "                    snn = torch.min(pos_dists,neg_dists) / torch.max(pos_dists,neg_dists)\n",
    "                    snn[torch.isnan(snn)] = 1.0\n",
    "                    #precision, recall, thresholds = precision_recall_curve(correct, 1-snn)\n",
    "                    ap = average_precision_score(correct, 1-snn)\n",
    "                    #prec_per_img.append(precision)\n",
    "                    #rec_per_img.append(recall)\n",
    "                    #ths_per_img.append(thresholds)\n",
    "                    aps.append(ap)\n",
    "                current_batch = all_img_labels == img_labels_unique[-1].item()\n",
    "                descriptors = [descriptors[current_batch]]\n",
    "                all_img_labels = [all_img_labels[current_batch]]\n",
    "                all_labels = [all_labels[current_batch]]\n",
    "                gc.collect()\n",
    "    all_img_labels = torch.cat(all_img_labels)\n",
    "    descriptors = torch.cat(descriptors)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    for ii in img_labels_unique:\n",
    "        current_batch = all_img_labels == ii\n",
    "        cur_descs = descriptors[current_batch].cpu()\n",
    "        cur_labels = all_labels[current_batch].cpu()\n",
    "        NN = cur_labels.size(0)\n",
    "        \n",
    "        pos_matrix = (cur_labels[None].expand(NN,NN) == cur_labels[...,None].expand(NN,NN)) != (torch.eye(NN).to(cur_labels.device)>0)\n",
    "        #print ('pos_matrix_done')\n",
    "        neg = torch.zeros(NN).long()\n",
    "        if NN > 5000:\n",
    "            bs1 = 128\n",
    "            nb = (NN // bs1)  \n",
    "            for bi in range(nb):\n",
    "                st = bi*bs1\n",
    "                fin = min(NN, (bi+1)*bs1)\n",
    "                if fin == st:\n",
    "                    break\n",
    "                dm = (torch.cdist(cur_descs[st:fin], cur_descs) +\n",
    "                      1000.0 * (pos_matrix[st:fin].to(cur_descs.dtype)) + \n",
    "                      1000.0*torch.eye(NN)[st:fin].to(cur_labels.device).to(cur_descs.dtype))\n",
    "                min_idx = torch.min(dm, dim=1)[1]\n",
    "                neg[st:fin] = min_idx       \n",
    "        pos_idxs = torch.arange(NN)[None].expand(NN,NN)[pos_matrix]\n",
    "        anc_idxs = torch.nonzero(pos_matrix)[:,0]\n",
    "        pos_matrix = None\n",
    "        neg_idxs = neg[anc_idxs]\n",
    "        pos_dists = F.pairwise_distance(cur_descs[anc_idxs], cur_descs[pos_idxs])\n",
    "        neg_dists = F.pairwise_distance(cur_descs[anc_idxs], cur_descs[neg_idxs])\n",
    "        correct = pos_dists <= neg_dists\n",
    "        snn = torch.min(pos_dists,neg_dists) / torch.max(pos_dists,neg_dists)\n",
    "        snn[torch.isnan(snn)] = 1.0\n",
    "        #precision, recall, thresholds = precision_recall_curve(correct, 1-snn)\n",
    "        #prec_per_img.append(precision)\n",
    "        #rec_per_img.append(recall)\n",
    "        #ths_per_img.append(thresholds)\n",
    "        ap = average_precision_score(correct, 1-snn)\n",
    "        aps.append(ap)\n",
    "    descriptors = None\n",
    "    all_labels = None\n",
    "    all_img_labels = None\n",
    "    dataset=None\n",
    "    dl_train = None\n",
    "    gc.collect()\n",
    "    return aps\n",
    "    #return {\"precision\": prec_per_img, \"recall\": rec_per_img, \"thresholds\": ths_per_img}\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "from collections import defaultdict\n",
    "results = defaultdict(dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notredame\n",
      "TFeat\n",
      "# Found cached data /home/mishkdmy/datasets/Brown/notredame.pt\n",
      "Extracting descriptors and calculating AP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='458' class='' max='458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [458/458 03:42<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mishkdmy/.conda/envs/fastai1/lib/python3.7/site-packages/ipykernel_launcher.py:79: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFeat mAP = 0.626\n",
      "yosemite\n",
      "TFeat\n",
      "# Found cached data /home/mishkdmy/datasets/Brown/yosemite.pt\n",
      "Extracting descriptors and calculating AP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='619' class='' max='619' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [619/619 02:18<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFeat mAP = 0.731\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "results = defaultdict(dict)\n",
    "for ds_name in val_ds_names:\n",
    "    print (ds_name)\n",
    "    for desc, desc_name in zip([\n",
    "         tfeat], ['TFeat']):\n",
    "        print (desc_name)\n",
    "        results[ds_name][desc_name] = eval_descriptor_on_dataset(desc,\n",
    "                                                                 ds_name, resol=50)\n",
    "        print (f'{desc_name} mAP = {np.array(results[ds_name][desc_name]).mean():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-08 17:51:35--  https://github.com/lg-zhang/dynamic-soft-margin-pytorch/raw/master/pretrained/liberty_float/model.state_dict\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/lg-zhang/dynamic-soft-margin-pytorch/master/pretrained/liberty_float/model.state_dict [following]\n",
      "--2020-09-08 17:51:36--  https://raw.githubusercontent.com/lg-zhang/dynamic-soft-margin-pytorch/master/pretrained/liberty_float/model.state_dict\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.16.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.16.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5347698 (5.1M) [application/octet-stream]\n",
      "Saving to: ‘model.state_dict’\n",
      "\n",
      "100%[======================================>] 5,347,698   28.7MB/s   in 0.2s   \n",
      "\n",
      "2020-09-08 17:51:44 (28.7 MB/s) - ‘model.state_dict’ saved [5347698/5347698]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/lg-zhang/dynamic-soft-margin-pytorch/raw/master/pretrained/liberty_float/model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HardNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (17): ReLU()\n",
       "    (18): Dropout(p=0.3, inplace=False)\n",
       "    (19): Conv2d(128, 128, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
       "    (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmargin = K.feature.HardNet(False)\n",
    "softmargin.load_state_dict(torch.load('model.state_dict'))\n",
    "softmargin.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notredame\n",
      "Dynamic SoftMargin\n",
      "# Found cached data /home/mishkdmy/datasets/Brown/notredame.pt\n",
      "Extracting descriptors and calculating AP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='458' class='' max='458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [458/458 03:42<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic SoftMargin mAP = 0.688\n",
      "yosemite\n",
      "Dynamic SoftMargin\n",
      "# Found cached data /home/mishkdmy/datasets/Brown/yosemite.pt\n",
      "Extracting descriptors and calculating AP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='619' class='' max='619' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [619/619 02:19<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic SoftMargin mAP = 0.775\n"
     ]
    }
   ],
   "source": [
    "#from collections import defaultdict\n",
    "#results = defaultdict(dict)\n",
    "for ds_name in val_ds_names:\n",
    "    print (ds_name)\n",
    "    for desc, desc_name in zip([\n",
    "         softmargin], ['Dynamic SoftMargin']):\n",
    "        print (desc_name)\n",
    "        results[ds_name][desc_name] = eval_descriptor_on_dataset(desc,\n",
    "                                                                 ds_name, resol=50)\n",
    "        print (f'{desc_name} mAP = {np.array(results[ds_name][desc_name]).mean():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notredame\n",
      "RootSIFT\n",
      "# Found cached data /home/mishkdmy/datasets/Brown/notredame.pt\n",
      "Extracting descriptors and calculating AP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='458' class='' max='458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [458/458 04:12<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mishkdmy/.conda/envs/fastai1/lib/python3.7/site-packages/ipykernel_launcher.py:79: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RootSIFT mAP = 0.579\n",
      "SIFT\n",
      "# Found cached data /home/mishkdmy/datasets/Brown/notredame.pt\n",
      "Extracting descriptors and calculating AP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='458' class='' max='458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [458/458 04:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT mAP = 0.569\n",
      "HardNet\n",
      "# Found cached data /home/mishkdmy/datasets/Brown/notredame.pt\n",
      "Extracting descriptors and calculating AP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='458' class='' max='458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [458/458 03:50<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HardNet mAP = 0.686\n",
      "SOSNet\n",
      "# Found cached data /home/mishkdmy/datasets/Brown/notredame.pt\n",
      "Extracting descriptors and calculating AP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='458' class='' max='458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [458/458 04:14<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOSNet mAP = 0.688\n",
      "yosemite\n",
      "RootSIFT\n",
      "# Found cached data /home/mishkdmy/datasets/Brown/yosemite.pt\n",
      "Extracting descriptors and calculating AP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='619' class='' max='619' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [619/619 04:02<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RootSIFT mAP = 0.682\n",
      "SIFT\n",
      "# Found cached data /home/mishkdmy/datasets/Brown/yosemite.pt\n",
      "Extracting descriptors and calculating AP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='619' class='' max='619' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [619/619 04:41<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT mAP = 0.685\n",
      "HardNet\n",
      "# Found cached data /home/mishkdmy/datasets/Brown/yosemite.pt\n",
      "Extracting descriptors and calculating AP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='619' class='' max='619' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [619/619 03:44<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HardNet mAP = 0.777\n",
      "SOSNet\n",
      "# Found cached data /home/mishkdmy/datasets/Brown/yosemite.pt\n",
      "Extracting descriptors and calculating AP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='619' class='' max='619' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [619/619 04:14<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOSNet mAP = 0.776\n"
     ]
    }
   ],
   "source": [
    "#from collections import defaultdict\n",
    "#results = defaultdict(dict)\n",
    "for ds_name in val_ds_names:\n",
    "    print (ds_name)\n",
    "    for desc, desc_name in zip([\n",
    "         K.feature.SIFTDescriptor(32, rootsift=True).to(torch.device('cuda:0')),\n",
    "         K.feature.SIFTDescriptor(32, rootsift=False).to(torch.device('cuda:0')),\n",
    "        K.feature.HardNet(True),\n",
    "        K.feature.SOSNet(True)], ['RootSIFT', 'SIFT', 'HardNet', 'SOSNet']):\n",
    "        print (desc_name)\n",
    "        results[ds_name][desc_name] = eval_descriptor_on_dataset(desc,\n",
    "                                                                 ds_name, resol=50)\n",
    "        print (f'{desc_name} mAP = {np.array(results[ds_name][desc_name]).mean():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-08 18:06:05--  https://github.com/DagnyT/hardnet/raw/master/pretrained/3rd_party/HardNetPS/HardNetPS.pth\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/DagnyT/hardnet/master/pretrained/3rd_party/HardNetPS/HardNetPS.pth [following]\n",
      "--2020-09-08 18:06:05--  https://raw.githubusercontent.com/DagnyT/hardnet/master/pretrained/3rd_party/HardNetPS/HardNetPS.pth\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.16.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.16.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5351453 (5.1M) [application/octet-stream]\n",
      "Saving to: ‘HardNetPS.pth.1’\n",
      "\n",
      "100%[======================================>] 5,351,453   30.4MB/s   in 0.2s   \n",
      "\n",
      "2020-09-08 18:06:13 (30.4 MB/s) - ‘HardNetPS.pth.1’ saved [5351453/5351453]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class HardNetPS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HardNetPS, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=3, padding=1, bias = True),\n",
    "        nn.BatchNorm2d(32, affine=True),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 32, kernel_size=3, padding=1, bias = True),\n",
    "        nn.BatchNorm2d(32, affine=True),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1, bias = True),\n",
    "        nn.BatchNorm2d(64, affine=True),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(64, 64, kernel_size=3, padding=1, bias = True),\n",
    "        nn.BatchNorm2d(64, affine=True),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(64, 128, kernel_size=3, stride=2,padding=1, bias = True),\n",
    "        nn.BatchNorm2d(128, affine=True),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(128, 128, kernel_size=3, padding=1, bias = True),\n",
    "        nn.BatchNorm2d(128, affine=True),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(128, 128, kernel_size=8, bias = True)\n",
    "    )\n",
    "    def input_norm(self,x):\n",
    "        flat = x.view(x.size(0), -1)\n",
    "        mp = torch.mean(flat, dim=1)\n",
    "        sp = torch.std(flat, dim=1) + 1e-7\n",
    "        return (x - mp.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand_as(x)) / sp.unsqueeze(-1).unsqueeze(-1).unsqueeze(1).expand_as(x)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x_features = self.features(self.input_norm(input))\n",
    "        x = x_features.view(x_features.size(0), -1)\n",
    "        return F.normalize(x, dim=1, p=2)\n",
    "hnps = HardNetPS()\n",
    "!wget https://github.com/DagnyT/hardnet/raw/master/pretrained/3rd_party/HardNetPS/HardNetPS.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HardNetPS(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU()\n",
       "    (18): Conv2d(128, 128, kernel_size=(8, 8), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hnps.load_state_dict(torch.load('HardNetPS.pth'))\n",
    "hnps.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notredame\n",
      "HardNetPS\n",
      "# Found cached data /home/mishkdmy/datasets/Brown/notredame.pt\n",
      "Extracting descriptors and calculating AP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='458' class='' max='458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [458/458 03:42<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HardNetPS mAP = 0.592\n",
      "yosemite\n",
      "HardNetPS\n",
      "# Found cached data /home/mishkdmy/datasets/Brown/yosemite.pt\n",
      "Extracting descriptors and calculating AP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='89' class='' max='619' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      14.38% [89/619 00:17<01:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-718144b0ff1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdesc_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         results[ds_name][desc_name] = eval_descriptor_on_dataset(desc,\n\u001b[0;32m----> 9\u001b[0;31m                                                                  ds_name, resol=50)\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'{desc_name} mAP = {np.array(results[ds_name][desc_name]).mean():.3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-befaf381a5f6>\u001b[0m in \u001b[0;36meval_descriptor_on_dataset\u001b[0;34m(desc, ds_name, resol, device, ds_root)\u001b[0m\n\u001b[1;32m     72\u001b[0m                             dm = (torch.cdist(cur_descs[st:fin], cur_descs) +\n\u001b[1;32m     73\u001b[0m                                   \u001b[0;36m1000.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpos_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_descs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                                 1000.0*torch.eye(NN)[st:fin].to(cur_labels.device).to(cur_descs.dtype))\n\u001b[0m\u001b[1;32m     75\u001b[0m                             \u001b[0mmin_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                             \u001b[0mneg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#from collections import defaultdict\n",
    "#results = defaultdict(dict)\n",
    "for ds_name in val_ds_names:\n",
    "    print (ds_name)\n",
    "    for desc, desc_name in zip([\n",
    "         hnps], ['HardNetPS']):\n",
    "        print (desc_name)\n",
    "        results[ds_name][desc_name] = eval_descriptor_on_dataset(desc,\n",
    "                                                                 ds_name, resol=50)\n",
    "        print (f'{desc_name} mAP = {np.array(results[ds_name][desc_name]).mean():.3f}')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reslist = [ 0.569,0.579,  0.592, 0.626, 0.686, 0.688, 0.688, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "size=25\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (20,8),\n",
    "          'axes.labelsize': size,\n",
    "          'axes.titlesize': size,\n",
    "          'xtick.labelsize': size*0.75,\n",
    "          'ytick.labelsize': size*0.75,\n",
    "          'axes.titlepad': 25}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "#plt.bar(np.arange(len(reslist)), reslist)\n",
    "#plt.figure(figsize=(12,8))\n",
    "for i in range(len(reslist)):\n",
    "    plt.bar(2*i, reslist[i])\n",
    "#plt.legend( ['SIFT', 'RootSIFT', 'TFeatLib', \"HardNet\", \"SOSNet\", \"DynSoftMargin\"])\n",
    "plt.ylabel('SNN mAP Notredame')\n",
    "plt.ylabel('SNN mAP Notredame')\n",
    "\n",
    "plt.xticks(2*np.arange(len(reslist)), ['SIFT', 'RootSIFT', 'HardNetPS', 'TFeatLib', \"HardNet\", \"SOSNet\", \"SoftMargin\"])\n",
    "#plt.legend()\n",
    "plt.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds_name in val_ds_names:\n",
    "    print (ds_name)\n",
    "    for desc, desc_name in zip([\n",
    "         K.feature.SIFTDescriptor(32, rootsift=True).to(torch.device('cuda:0')),\n",
    "         K.feature.SIFTDescriptor(32, rootsift=False).to(torch.device('cuda:0')),\n",
    "        K.feature.HardNet(True),\n",
    "        K.feature.SOSNet(True)], ['RootSIFT', 'SIFT', 'HardNet', 'SOSNet']):\n",
    "        print (desc_name)\n",
    "        results[ds_name][desc_name] = eval_descriptor_on_dataset(desc,\n",
    "                                                                 ds_name, resol=50)\n",
    "        print (f'{desc_name} mAP = {np.array(results[ds_name][desc_name]).mean():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
